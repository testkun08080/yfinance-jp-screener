# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Repository Overview

**å€‹äººå‘ã‘æ—¥æœ¬æ ªå¼åˆ†æãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ** - yfinance APIã‚’æ´»ç”¨ã—ãŸ3795+éŠ˜æŸ„ã®å°å‹æ ªåˆ†æãƒ„ãƒ¼ãƒ«

ã“ã®ãƒªãƒã‚¸ãƒˆãƒªã¯å€‹äººé–‹ç™ºãƒ»å€‹äººç’°å¢ƒã§ã®ä½¿ç”¨ã‚’æƒ³å®šã—ãŸã€ã‚·ãƒ³ãƒ—ãƒ«ã§åŠ¹ç‡çš„ãªæ ªå¼åˆ†æã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚

### ã‚·ã‚¹ãƒ†ãƒ æ§‹æˆ

**1. ãƒ‡ãƒ¼ã‚¿åé›†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³** (Python 3.11)
- JPXå…¬å¼ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æœ€æ–°æ ªå¼ãƒªã‚¹ãƒˆè‡ªå‹•å–å¾—
- yfinance APIã«ã‚ˆã‚‹è²¡å‹™ãƒ‡ãƒ¼ã‚¿åé›†
- 4æ®µéšSequentialå®Ÿè¡Œã§APIåˆ¶é™ãƒ»ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå›é¿
- è‡ªå‹•CSVçµåˆæ©Ÿèƒ½

**2. Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³** (React 19 + TypeScript + Vite)
- ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ­ãƒ¼ã‚«ãƒ«ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆSEOãƒ»PWAå‰Šé™¤æ¸ˆã¿ï¼‰
- å‹•çš„ã‚«ãƒ©ãƒ æ¤œå‡ºãƒ»æ—¥æœ¬èªé‡‘èãƒ‡ãƒ¼ã‚¿å¯¾å¿œ
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¤œç´¢ãƒ»ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
- ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–ãƒ‡ã‚¶ã‚¤ãƒ³ï¼ˆTailwind CSS + DaisyUIï¼‰

**3. Dockerç’°å¢ƒ** (nginx + Python)
- æœ¬ç•ªåŒç­‰ã®å®Ÿè¡Œç’°å¢ƒ
- ãƒãƒ«ãƒã‚¹ãƒ†ãƒ¼ã‚¸ãƒ“ãƒ«ãƒ‰æœ€é©åŒ–
- ãƒœãƒªãƒ¥ãƒ¼ãƒ å…±æœ‰ã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿é€£æº
- nginxã«ã‚ˆã‚‹é«˜é€Ÿé™çš„ãƒ•ã‚¡ã‚¤ãƒ«é…ä¿¡

**4. GitHub Actions CI** (7ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼)
- Sequential Stock Fetch (Part 1-4): å„120åˆ†å®Ÿè¡Œ
- CSV Combine & Export
- Stock List Update
- Stock Data Fetch (å˜ä½“ãƒ†ã‚¹ãƒˆç”¨)

### é‡è¦ãªè¨­è¨ˆæ–¹é‡

âœ… **å€‹äººç’°å¢ƒç‰¹åŒ–**
- SEOæœ€é©åŒ–ä¸è¦ï¼ˆå‰Šé™¤æ¸ˆã¿ï¼‰
- PWAæ©Ÿèƒ½ä¸è¦ï¼ˆå‰Šé™¤æ¸ˆã¿ï¼‰
- GitHub Pagesä¸è¦ï¼ˆå‰Šé™¤æ¸ˆã¿ï¼‰
- ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ­ãƒ¼ã‚«ãƒ«/Dockerå®Ÿè¡Œ

âœ… **è‡ªå‹•åŒ–é‡è¦–**
- ãƒ‡ãƒ¼ã‚¿åé›†ã®å®Œå…¨è‡ªå‹•åŒ–
- ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ»ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½
- ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼é€£é–å®Ÿè¡Œ

âœ… **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–**
- ãƒ™ãƒ³ãƒ€ãƒ¼ãƒãƒ£ãƒ³ã‚¯åˆ†é›¢
- nginxé™çš„é…ä¿¡
- Docker build cacheæ´»ç”¨

### ğŸ“š è©³ç´°ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

å„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®è©³ç´°ãªèª¬æ˜ã¯ã€ãã‚Œãã‚Œã®READMEã‚’å‚ç…§ã—ã¦ãã ã•ã„ï¼š

- **[stock_list/README.md](stock_list/README.md)** - ãƒ‡ãƒ¼ã‚¿åé›†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®è©³ç´°ï¼ˆPython scripts, CSV processingï¼‰
- **[stock_search/README.md](stock_search/README.md)** - React Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®è©³ç´°ï¼ˆFrontend, build processï¼‰
- **[README.md](README.md)** - ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå…¨ä½“ã®æ¦‚è¦ã¨ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

## Repository Structure

```
yfinance-jp-screener/
â”œâ”€â”€ .github/workflows/                    # GitHub Actions automation (7 workflows)
â”‚   â”œâ”€â”€ stock-data-fetch.yml             # Manual: Single stock file processing
â”‚   â”œâ”€â”€ stock-fetch-sequential-1.yml     # Automated: Part 1/4 â†’ triggers Part 2
â”‚   â”œâ”€â”€ stock-fetch-sequential-2.yml     # Automated: Part 2/4 â†’ triggers Part 3
â”‚   â”œâ”€â”€ stock-fetch-sequential-3.yml     # Automated: Part 3/4 â†’ triggers Part 4
â”‚   â”œâ”€â”€ stock-fetch-sequential-4.yml     # Automated: Part 4/4 â†’ triggers CSV combine
â”‚   â”œâ”€â”€ csv-combine-export.yml           # Automated: Combine CSVs
â”‚   â””â”€â”€ stock-list-update.yml            # Manual: Stock list updates and splitting
â”œâ”€â”€ current/                              # Personal portfolio data
â”‚   â””â”€â”€ tes.md                           # Portfolio tracking file
â”œâ”€â”€ stock_list/                           # Data collection and processing
â”‚   â”œâ”€â”€ Export/                          # Generated CSV data exports (gitignored in production)
â”‚   â”œâ”€â”€ combine_latest_csv.py            # CSV combination script
â”‚   â”œâ”€â”€ sumalize.py                      # Main data collection script with yfinance
â”‚   â”œâ”€â”€ split_stocks.py                  # JSON file splitting utility (enhanced CLI)
â”‚   â”œâ”€â”€ get_jp_stocklist.py              # Stock list acquisition from JPX
â”‚   â”œâ”€â”€ stocks_all.json                  # Master stock list (~3795 companies)
â”‚   â”œâ”€â”€ stocks_1.json                    # Split 1: Companies 1-1000
â”‚   â”œâ”€â”€ stocks_2.json                    # Split 2: Companies 1001-2000
â”‚   â”œâ”€â”€ stocks_3.json                    # Split 3: Companies 2001-3000
â”‚   â”œâ”€â”€ stocks_4.json                    # Split 4: Companies 3001-3795
â”‚   â”œâ”€â”€ requirements.txt                 # Python dependencies (pandas, yfinance, etc.)
â”‚   â””â”€â”€ pyproject.toml                   # Python project configuration
â”œâ”€â”€ search/                                # Research and analysis data
â”‚   â”œâ”€â”€ kogata/                          # Small-cap company data by industry
â”‚   â”‚   â”œâ”€â”€ *.csv                        # Industry-specific financial data (23 sectors)
â”‚   â”œâ”€â”€ high_netcash/                    # High net cash companies analysis
â”‚   â”‚   â”œâ”€â”€ *.csv                        # Sector-specific high net cash data
â”‚   â”‚   â”œâ”€â”€ summary_data.json            # Analysis summary
â”‚   â”‚   â””â”€â”€ é«˜ãƒãƒƒãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥æ¯”ç‡ä¼æ¥­åˆ†æ.md
â”‚   â””â”€â”€ çµ±åˆãƒ‡ãƒ¼ã‚¿*.csv                   # Consolidated datasets
â”œâ”€â”€ stock_search/                         # Web application (React + TypeScript + Vite)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/                  # React components
â”‚   â”‚   â”‚   â”œâ”€â”€ DataTable.tsx           # Dynamic CSV display
â”‚   â”‚   â”‚   â”œâ”€â”€ FileUpload.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ SearchFilters.tsx
â”‚   â”‚   â”‚   â””â”€â”€ Pagination.tsx
â”‚   â”‚   â”œâ”€â”€ hooks/                       # Custom React hooks
â”‚   â”‚   â”‚   â”œâ”€â”€ useCSVParser.ts
â”‚   â”‚   â”‚   â””â”€â”€ useFilters.ts
â”‚   â”‚   â”œâ”€â”€ utils/                       # Utility functions
â”‚   â”‚   â”‚   â”œâ”€â”€ csvParser.ts            # CSV parsing and formatting
â”‚   â”‚   â”‚   â”œâ”€â”€ csvDownload.ts          # CSV download utilities
â”‚   â”‚   â”‚   â””â”€â”€ columnConfig.ts         # Column configuration utilities
â”‚   â”‚   â”œâ”€â”€ types/                       # TypeScript definitions
â”‚   â”‚   â”‚   â””â”€â”€ stock.ts
â”‚   â”‚   â””â”€â”€ App.tsx                      # Main application
â”‚   â”œâ”€â”€ public/                          # Public assets
â”‚   â”‚   â””â”€â”€ favicon.ico                  # Favicon
â”‚   â”œâ”€â”€ dist/                            # Built application
â”‚   â”œâ”€â”€ nginx.conf                       # Nginx configuration for Docker production
â”‚   â”œâ”€â”€ package.json                     # Node.js dependencies
â”‚   â”œâ”€â”€ vite.config.ts                   # Vite configuration
â”‚   â””â”€â”€ tsconfig.json                    # TypeScript configuration
â”œâ”€â”€ Dockerfile.fetch                     # Python service (data collection)
â”œâ”€â”€ Dockerfile.app                   # Frontend service (nginx production)
â”œâ”€â”€ docker-compose.yml                    # Docker orchestration configuration
â”œâ”€â”€ .env.sample                          # Environment variables template
â”œâ”€â”€ CLAUDE.md                            # This file
â”œâ”€â”€ DOCKER.md                            # Docker deployment documentation
â””â”€â”€ README.md                            # Project documentation
```

## System Components

### 1. Data Collection Pipeline (`stock_list/`)

**Core Scripts:**
- `sumalize.py` - Main data collection script with yfinance API integration
- `split_stocks.py` - Enhanced utility with command-line arguments for flexible file splitting
- `get_jp_stocklist.py` - Stock list acquisition from JPX official data sources
- `combine_latest_csv.py` - Combines multiple CSV exports into single dated file

**Data Processing Features:**
- **Enhanced CLI**: `split_stocks.py` supports `--input`, `--size`, and `--verbose` flags
- Flexible input file specification (default: `stocks_all.json`)
- Customizable chunk sizes for different use cases
- Comprehensive logging with execution time tracking
- Error handling and retry mechanisms for API failures
- Rate limiting for API compliance and stability
- Automatic CSV generation with timestamping
- Master stock list management (`stocks_all.json`)

**Usage Examples:**
```bash
# Process default file
python sumalize.py

# Process specific chunk
python sumalize.py stocks_1.json

# Update master stock list
python get_jp_stocklist.py

# Enhanced split functionality with arguments
python split_stocks.py --input stocks_all.json --size 1000
python split_stocks.py -i custom_data.json -s 500 --verbose

# Combine latest CSV files
python combine_latest_csv.py
python combine_latest_csv.py --date 20251006
```

### 2. Web Application (`stock_search/`)

**Technology Stack:**
- **Frontend**: React 19 + TypeScript + Vite
- **Styling**: Tailwind CSS + DaisyUI
- **State Management**: Custom hooks with local state
- **CSV Processing**: Papa Parse with Japanese character support
- **Deployment**: Docker with nginx

**Key Features:**
- Dynamic column detection and display for any CSV structure
- Japanese financial data formatting (å††, %, å€)
- Real-time search and filtering capabilities
- Responsive design with sticky columns for mobile compatibility
- Pagination and sorting capabilities
- **Drag & Drop File Upload** - CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç°¡å˜ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
- Optimized bundle splitting for performance
- Client-side CSV processing with zero server dependency

**File Upload System:**
- **Method**: Drag & Drop ã¾ãŸã¯ ã‚¯ãƒªãƒƒã‚¯é¸æŠ
- **Format**: CSV files (any structure supported)
- **Processing**: Client-side with Papa Parse library
- **Benefits**: ã‚·ãƒ³ãƒ—ãƒ«ã€é«˜é€Ÿã€ã‚µãƒ¼ãƒãƒ¼ä¸è¦

**Build Process:**
1. **Build**: `tsc -b && vite build` - TypeScript compilation + Vite bundling
2. **Output**: `dist/` directory with optimized vendor chunks
3. **Runtime**: Client-side CSV file upload and processing

**Docker Deployment:**
- **Container**: nginx:alpine serving static build
- **Volume**: CSV files mounted from shared volume
- **Performance**: Vendor chunks separated for efficient caching
- **Access**: http://localhost:8080

### 3. Docker Environment

**Two-Service Architecture:**

#### **Python Service** (`Dockerfile.fetch`)
- **Base Image**: python:3.11-slim
- **Purpose**: Data collection and processing
- **Working Directory**: `/app`
- **Volumes**:
  - `./stock_list:/app:rw` - Scripts and stock list files
  - `stock-data:/app/Export:rw` - Named volume for CSV exports (simplified)
- **Default Command**: Sequential execution of:
  1. `get_jp_stocklist.py` - Fetch latest stock list
  2. `split_stocks.py` - Split into chunks
  3. `sumalize.py` - Collect financial data
  4. `combine_latest_csv.py` - Combine CSV files
- **Environment Variables**:
  - `STOCK_FILE` - Stock file to process (default: stocks_1.json)
  - `CHUNK_SIZE` - Split chunk size (default: 1000)
- **Export Directory**: Uses `Export/` directly (not `stock_list/Export/`)

#### **Frontend Service** (`Dockerfile.app`)
- **Base Image**: nginx:alpine (production)
- **Multi-stage Build**:
  1. **Builder Stage**: Node.js 20 - builds React application
  2. **Runner Stage**: nginx - serves static files
- **Working Directory**: `/usr/share/nginx/html`
- **Volumes**: `stock-data:/usr/share/nginx/html/csv:ro` - Named volume (read-only)
- **Port**: 80 (exposed as 8080 on host)
- **Configuration**: Custom nginx.conf with:
  - SPA routing support
  - Gzip compression
  - Static asset caching
  - CSV file CORS headers
  - Security headers

**Data Flow (Simplified with Named Volume):**
```
Python Container â†’ /app/Export (combine_latest_csv.py writes CSV)
       â†“
  stock-data volume (named Docker volume)
       â†“
Frontend Container â†’ /usr/share/nginx/html/csv (nginx serves from volume)
       â†“
  Browser access: http://localhost:8080/csv/YYYYMMDD_combined.csv
```

**Docker Compose Configuration:**
- **Network**: `stock-network` (bridge driver)
- **Volume**: `stock-data` (named volume, local driver) - shared between services
- **Dependencies**: Frontend depends on Python service completion
- **Health Checks**: Frontend HTTP health check on port 80
- **Restart Policy**: Python service runs once, Frontend always available
- **Directory Structure**: Uses `Export/` directly instead of `stock_list/Export/`

**Usage:**
```bash
# Start both services
docker-compose up --build

# Access frontend
open http://localhost:8080

# View logs
docker-compose logs -f

# Stop services
docker-compose down

# Clean volumes
docker-compose down -v
```

### 4. GitHub Actions Automation (`.github/workflows/`)

**Workflow Orchestration Chain:**

```
Sequential Data Collection Workflows (Manual Start)
    â†“
stock-fetch-sequential-1.yml (Part 1/4)
    â†“ Auto-trigger on success
stock-fetch-sequential-2.yml (Part 2/4)
    â†“ Auto-trigger on success
stock-fetch-sequential-3.yml (Part 3/4)
    â†“ Auto-trigger on success
stock-fetch-sequential-4.yml (Part 4/4)
    â†“ Auto-trigger on success
csv-combine-export.yml (Combine all CSV files)
    â†“
CSV Data Ready for Local/Docker Use
```

#### **Workflow 1: `stock-data-fetch.yml` (Manual Single File Processing)**
- **Trigger**: Manual (workflow_dispatch)
- **Purpose**: Process single stock file for quick testing
- **Input**: Stock file selection (stocks_1.json - stocks_4.json, stocks_sample.json)
- **Timeout**: 60 minutes
- **Process**: Data collection â†’ Export to stock_list/Export/ â†’ Commit
- **Use Case**: Quick data collection for specific stock chunk

#### **Workflow 2-5: Sequential Stock Fetch Workflows**
**Part 1** (`stock-fetch-sequential-1.yml`):
- **Trigger**: Manual (workflow_dispatch)
- **Process**: stocks_1.json â†’ Commit â†’ Auto-trigger Part 2
- **Timeout**: 120 minutes

**Part 2** (`stock-fetch-sequential-2.yml`):
- **Trigger**: Auto (triggered by Part 1 completion)
- **Process**: stocks_2.json â†’ Commit â†’ Auto-trigger Part 3

**Part 3** (`stock-fetch-sequential-3.yml`):
- **Trigger**: Auto (triggered by Part 2 completion)
- **Process**: stocks_3.json â†’ Commit â†’ Auto-trigger Part 4

**Part 4 (Final)** (`stock-fetch-sequential-4.yml`):
- **Trigger**: Auto (triggered by Part 3 completion)
- **Process**: stocks_4.json â†’ Commit â†’ Auto-trigger CSV Combine
- **Special**: Completion summary and workflow chain trigger

**Why Sequential?**
- Avoids API rate limiting from yfinance
- Prevents GitHub Actions timeout (max 6 hours total, 120 min per workflow)
- Allows monitoring and intervention at each stage
- Commits data incrementally for safety

#### **Workflow 6: `csv-combine-export.yml` (CSV Combination)**
- **Trigger**:
  - Auto (triggered by Sequential Part 4 completion)
  - Manual (workflow_dispatch)
- **Purpose**: Combine all japanese_stocks_data_*.csv files into single dated file
- **Input Parameters** (manual only):
  - `custom_date` - Custom date for output filename (YYYYMMDD)
  - `reason` - Reason for combination
- **Process**:
  1. Check existing CSV files in stock_list/Export/
  2. Run `combine_latest_csv.py` with arguments
  3. Commit combined file (YYYYMMDD_combined.csv)
- **Output**: `YYYYMMDD_combined.csv` in stock_list/Export/

#### **Workflow 7: `stock-list-update.yml` (Master List Update)**
- **Trigger**: Manual (workflow_dispatch)
- **Purpose**: Update master stock list from JPX
- **Process**:
  1. Run `get_jp_stocklist.py` to fetch latest JPX data
  2. Generate `stocks_all.json` (~3795 companies)
  3. Split using `split_stocks.py --input stocks_all.json --size 1000`
  4. Validate all generated JSON files
  5. Commit with Japanese date format
- **Output**: Updated stocks_all.json and stocks_1-4.json
- **Frequency**: Run when JPX publishes new stock listings (monthly/quarterly)

### 5. CSV Data Flow Architecture

**Important Note on Directory Paths:**
- **GitHub Actions & Local Development**: Uses `stock_list/Export/` (repository structure)
- **Docker Environment**: Uses `Export/` directly (simplified with named volumes)
- **Python Scripts**: Use relative path `Export/` which works in both contexts

**CSV File Upload System (Drag & Drop):**
- **Method**: Client-side file upload only (no server required)
- **Processing**: Papa Parse library for CSV parsing
- **Benefits**: ã‚·ãƒ³ãƒ—ãƒ«ã€é«˜é€Ÿã€ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ãƒ•ãƒªãƒ¼ã€å®Œå…¨ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚µã‚¤ãƒ‰

**Application Flow:**

#### **Local Development**
```
npm run dev â†’ http://localhost:5173
    â†“
User drags & drops CSV file
    â†“
FileUpload component receives file
    â†“
Papa Parse processes CSV client-side
    â†“
DataTable displays results
```

#### **Production Build**
```
npm run build
    â†“
Vite build â†’ dist/ directory
    â†“
Static files ready for deployment
    â†“
User uploads CSV via browser (D&D or click)
```

#### **Docker Deployment**
```
docker-compose up â†’ nginx serves static files
    â†“
Browser: http://localhost:8080
    â†“
User uploads CSV file via drag & drop
    â†“
Client-side processing and display
```

**Key Features**:
- **Zero Server Dependency**: å®Œå…¨ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚µã‚¤ãƒ‰å‡¦ç†
- **Any CSV Structure**: ä»»æ„ã®CSVæ§‹é€ ã«å¯¾å¿œ
- **Fast Processing**: ãƒ–ãƒ©ã‚¦ã‚¶ä¸Šã§é«˜é€Ÿè§£æ
- **Simple Deployment**: é™çš„ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ï¼ˆnginx, GitHub Pages, S3ãªã©ï¼‰
- **Privacy**: ãƒ‡ãƒ¼ã‚¿ã¯ãƒ–ãƒ©ã‚¦ã‚¶å†…ã®ã¿ã§å‡¦ç†ï¼ˆã‚µãƒ¼ãƒãƒ¼ã«é€ä¿¡ã•ã‚Œãªã„ï¼‰

## Data Architecture

### Stock List Management

**Master Data Source**: JPX (Japan Exchange Group) official data
- **Source**: `https://www.jpx.co.jp/markets/statistics-equities/misc/tvdivq0000001vg2-att/data_j.xls`
- **Format**: Excel â†’ JSON conversion with Japanese character support
- **Markets**: ãƒ—ãƒ©ã‚¤ãƒ  (Prime), ã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰ (Standard), ã‚°ãƒ­ãƒ¼ã‚¹ (Growth)
- **Data Fields**: ã‚³ãƒ¼ãƒ‰ (Stock Code), éŠ˜æŸ„å (Company Name), å¸‚å ´ãƒ»å•†å“åŒºåˆ† (Market Classification), 33æ¥­ç¨®åŒºåˆ† (Industry Classification)

**File Structure:**
```
stocks_all.json      # Master list (~3795 companies)
â”œâ”€â”€ stocks_1.json    # Companies 1-1000
â”œâ”€â”€ stocks_2.json    # Companies 1001-2000
â”œâ”€â”€ stocks_3.json    # Companies 2001-3000
â””â”€â”€ stocks_4.json    # Companies 3001-3795
```

### Industry Data Structure (search/kogata/)

**Core Financial Fields:**
- **Basic Info**: ä¼šç¤¾å (Company Name), éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ (Stock Code), æ¥­ç¨® (Industry)
- **Market Data**: å„ªå…ˆå¸‚å ´ (Preferred Market), æ™‚ä¾¡ç·é¡ (Market Cap), æ±ºç®—æœˆ (Settlement Month)
- **Geographic**: éƒ½é“åºœçœŒ (Prefecture), ä¼šè¨ˆåŸºæº– (Accounting Standard)
- **Valuation Ratios**: PBR, ROE, è‡ªå·±è³‡æœ¬æ¯”ç‡ (Equity Ratio), PER(ä¼šäºˆ) (Projected PER)
- **Performance Metrics**: å£²ä¸Šé«˜ (Revenue), å–¶æ¥­åˆ©ç›Š (Operating Profit), å–¶æ¥­åˆ©ç›Šç‡ (Operating Margin)
- **Profitability**: å½“æœŸç´”åˆ©ç›Š (Net Profit), ç´”åˆ©ç›Šç‡ (Net Margin)
- **Balance Sheet**: è² å‚µ (Debt), æµå‹•è² å‚µ (Current Liabilities), æµå‹•è³‡ç”£ (Current Assets)
- **Cash Analysis**: ãƒãƒƒãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆæµå‹•è³‡ç”£-è² å‚µï¼‰, ãƒãƒƒãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥æ¯”ç‡
- **Additional Fields**: ç·è² å‚µ, ç¾é‡‘åŠã³ç¾é‡‘åŒç­‰ç‰©, æŠ•è³‡æœ‰ä¾¡è¨¼åˆ¸

**Data Quality Features:**
- Automatic data type detection and conversion
- Japanese unit parsing (å€, %, å††) with proper formatting
- Null value handling and validation
- Unicode support for Japanese characters
- Flexible schema adaptation for varying CSV structures

**Industry Sectors Available (23 sectors):**
- **Basic Industries**: åŒ–å­¦, é‰„é‹¼, éé‰„é‡‘å±, é‡‘å±è£½å“, ã‚´ãƒ 
- **Manufacturing**: æ©Ÿæ¢°, é›»æ°—æ©Ÿå™¨, é‹é€ç”¨, æ©Ÿå¯†è£½å“, ãƒ‘ãƒ«ãƒ—ãƒ»ç´™, ç¹Šç¶­
- **Services**: ã‚µãƒ¼ãƒ“ã‚¹, æƒ…å ±ãƒ»é€šä¿¡æ¥­, å€‰åº«ãƒ»é‹è¼¸é–¢é€£æ¥­
- **Consumer**: å°å£²æ¥­, å¸æ¥­è€…, é£Ÿæ–™å“
- **Real Estate & Finance**: ä¸å‹•ç”£æ¥­ç•Œ, è¨¼åˆ¸
- **Resources**: æ°´ç”£ãƒ»è¾²æ—æ¥­, çŸ³æ²¹ãƒ»çŸ³ç‚­è£½å“
- **Construction**: å»ºè¨­æ¥­ç•Œ
- **Other**: ãã®ä»–

## Development Context

This repository serves as a comprehensive Japanese stock analysis platform with:

### Japanese Business Focus
- **Language**: Primary data and interface in Japanese with Unicode support
- **Market**: Japanese stock exchanges (ãƒ—ãƒ©ã‚¤ãƒ , ã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰, ã‚°ãƒ­ãƒ¼ã‚¹)
- **Specialization**: Small-cap company (å°å‹æ ª) analysis and screening
- **Perspective**: Individual investor research with AI-assisted analysis
- **Cultural Context**: Japanese financial terminology and reporting standards

### Technical Environment
- **Backend**: Python 3.11+ (data processing and API integration)
- **Frontend**: React 19 + TypeScript + Vite (modern web interface)
- **Data Processing**: yfinance, pandas, Papa Parse
- **Deployment**: Docker + nginx (å€‹äººç’°å¢ƒå‘ã‘)
- **CSV Processing**: Robust handling of Japanese financial data formats
- **Version Control**: Git-based data versioning and change tracking
- **Containerization**: Docker Compose (nginx production + Python data service)

### Automation Strategy
- **Sequential Workflows**: Multi-part data collection to avoid timeouts and rate limits (GitHub Actions)
- **Workflow Orchestration**: Auto-triggered workflow chains for complete automation (7 workflows)
- **Data Pipeline**: Collection â†’ Combination â†’ Local/Docker Use
- **Quality Assurance**: Build verification, health checks, and error handling
- **Monitoring**: Comprehensive logging and artifact retention (30 days)

## Common Operations

### Data Collection Operations

**Full Sequential Collection (All 3795+ companies):**
```bash
# GitHub Actions (Recommended)
# 1. Navigate to Actions â†’ "ğŸ“Š Sequential Stock Fetch - Part 1"
# 2. Click "Run workflow"
# 3. Wait for all 4 parts to complete (automatic chain)
# 4. CSV combination happens automatically

# Expected duration: 6-8 hours total for all parts
```

**Quick Single File Collection:**
```bash
# GitHub Actions
# Navigate to Actions â†’ "ğŸ“Š Stock Data Fetch"
# Select stock file (stocks_1.json - stocks_4.json)
# Click "Run workflow"

# Expected duration: 1-2 hours per file
```

**Local Development:**
```bash
cd stock_list

# Collect data for specific chunk
python sumalize.py stocks_1.json

# Combine latest CSV files
python combine_latest_csv.py

# Check exports
ls -lh Export/*_combined.csv
```

### Web Application Development

**Local Development:**
```bash
cd stock_search

# Install dependencies
npm install

# Start development server with hot reload
npm run dev
# Access: http://localhost:5173

# Build for production
npm run build
# Output: dist/ directory with CSV files included

# Preview production build
npm run preview
# Access: http://localhost:4173

# Manually copy CSV files (normally done in prebuild)
npm run copy-csv
```

**Docker Development:**
```bash
# Build and start both services
docker-compose up --build

# Access frontend
open http://localhost:8080

# Check CSV files are accessible
curl http://localhost:8080/csv/

# View logs
docker-compose logs -f frontend-service

# Stop services
docker-compose down

# Clean volumes and rebuild
docker-compose down -v && docker-compose up --build
```

### CSV Combination & Docker Deployment

**CSV Combination:**
```bash
# GitHub Actions (Automated after Sequential Part 4)
# Navigate to Actions â†’ "ğŸ“‹ CSV Combine & Export"
# Combined CSV files in stock_list/Export/

# Local
cd stock_list
python combine_latest_csv.py
# or with custom date
python combine_latest_csv.py --date 20251006
```

**Docker Deployment:**
```bash
# Build and start both services (data collection + frontend)
docker-compose up --build

# Access application
open http://localhost:8080

# View logs
docker-compose logs -f

# Stop and clean
docker-compose down -v
```

### Stock List Update Operations

```bash
# GitHub Actions (when JPX publishes new listings)
# Navigate to Actions â†’ "ğŸ“‹ Stock List Update"
# Optionally provide reason
# Click "Run workflow"

# Local development
cd stock_list
python get_jp_stocklist.py
python split_stocks.py --input stocks_all.json --size 1000

# Verify splits
ls -lh stocks_*.json
```

## GitHub Actions Workflows

### Workflow Management Strategy

**Two-Tier Automation System:**
1. **Data Collection** (5 workflows)
   - `stock-data-fetch.yml` - Manual single file
   - `stock-fetch-sequential-1/2/3/4.yml` - Automated sequential chain

2. **Data Processing** (2 workflows)
   - `csv-combine-export.yml` - CSV combination
   - `stock-list-update.yml` - Master list updates

### Workflow Execution Best Practices

**For Complete Data Update:**
1. Start `stock-fetch-sequential-1.yml` manually
2. Wait for automatic completion of all 4 parts (6-8 hours)
3. Automatic CSV combination follows
4. CSV files available in stock_list/Export/
5. Deploy locally using Docker if needed

**For Quick Testing:**
1. Run `stock-data-fetch.yml` with `stocks_sample.json`
2. Manually run `csv-combine-export.yml` if needed
3. Test locally with Docker

**For Stock List Updates:**
1. Run `stock-list-update.yml` when JPX updates listings
2. Manually verify stocks_all.json and split files
3. Run sequential collection for new companies

### Error Handling and Monitoring

**Built-in Error Handling:**
- Timeout protection (60-120 minutes per workflow)
- Dependency validation before execution
- Build artifact verification
- Git conflict resolution with rebase
- Comprehensive error logging

**Monitoring Features:**
- Real-time workflow status in Actions tab
- Execution time tracking for performance metrics
- Build artifact retention (30 days) for debugging
- Commit messages with timestamps and completion status
- Health checks for deployed services

## Technical Specifications

### Japanese Language Support
- **Character Encoding**: UTF-8 throughout all components
- **Financial Terminology**: Native Japanese terms with English annotations
- **Geographic Data**: Prefecture-based analysis (éƒ½é“åºœçœŒ)
- **Accounting Standards**: Japan GAAP compliance and tracking
- **Market Classifications**: Japanese exchange-specific categories

### Performance Considerations
- **Data Volume**: 3795+ companies across 23+ industry sectors
- **Processing Time**: ~3-5 seconds per company via yfinance API
- **Sequential Processing**: 120 minutes timeout per workflow part
- **Web Interface**: Optimized for large datasets with pagination and lazy loading
- **Storage**: Efficient CSV compression and Git LFS considerations
- **Caching**:
  - Client-side data caching for improved UX
  - GitHub Actions npm/pip cache for faster builds
  - nginx static asset caching with proper headers
- **Bundle Optimization**: Vendor chunks separated for efficient loading

### Integration Points
- **yfinance API**: Primary data source with rate limiting and retry logic
- **JPX Official Data**: Stock list source with Excel â†’ JSON conversion
- **GitHub Actions**: 7 workflows with sequential orchestration
- **React Components**: Modular design for easy extension and maintenance
- **TypeScript**: Type safety for Japanese financial data structures
- **Tailwind CSS + DaisyUI**: Responsive design system
- **Docker + nginx**: Production-ready containerization with multi-stage builds
- **Papa Parse**: CSV parsing with Japanese character support

### Security and Compliance
- **API Rate Limiting**: Respectful usage of external APIs (yfinance, JPX)
- **Error Handling**: Graceful failure handling without data corruption
- **Version Control**: Complete audit trail of all data changes
- **Access Control**: GitHub repository permissions and workflow security
- **Data Validation**: Input validation and sanitization throughout pipeline
- **Docker Security**: Non-root users, minimal base images, proper permissions
- **nginx Security**: Security headers, CORS policies, XSS protection

## Development Workflow

### Local Development Process
1. **Environment Setup**: Python 3.11+ and Node.js 20+ required
2. **Data Development**: Work in `stock_list/` directory for data processing scripts
3. **Web Development**: Work in `stock_search/` directory for React application
4. **Testing**: Use provided test files and validation scripts
5. **Docker Testing**: Use docker-compose for integration testing
6. **Deployment**: Deploy using Docker Compose

### Docker Production Deployment
1. **Data Collection**: Run sequential workflows via GitHub Actions (6-8 hours)
2. **CSV Combination**: Automatic combination after Part 4
3. **Code Changes**: Modify files in `stock_search/` directory if needed
4. **Build & Deploy**: `docker-compose up --build` (builds both services)
5. **Verification**: Check application at http://localhost:8080
6. **Monitoring**: Use `docker-compose logs -f` for real-time logs

### Complete Data Update & Deployment Workflow
1. **Sequential Collection**: Start Part 1 workflow via GitHub Actions
2. **Automatic Chain**: Parts 2-4 execute automatically (6-8 hours)
3. **CSV Combination**: Automatic combination after Part 4 completion
4. **Local Access**: CSV files available in `stock_list/Export/`
5. **Docker Build**: `docker-compose up --build` for local deployment
6. **Verification**: Access application at http://localhost:8080

## ã‚·ã‚¹ãƒ†ãƒ æ¦‚è¦

å€‹äººå‘ã‘æ—¥æœ¬æ ªå¼åˆ†æãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã€‚GitHub Actionsã«ã‚ˆã‚‹è‡ªå‹•ãƒ‡ãƒ¼ã‚¿åé›†ã¨ã€Docker + nginxã«ã‚ˆã‚‹ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆã‚’æä¾›ã€‚

**ä¸»è¦æ©Ÿèƒ½:**
- JPXå…¬å¼ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã®æ ªå¼ãƒªã‚¹ãƒˆè‡ªå‹•å–å¾—ï¼ˆ3795+éŠ˜æŸ„ï¼‰
- yfinance APIã«ã‚ˆã‚‹è²¡å‹™ãƒ‡ãƒ¼ã‚¿åé›†
- 4æ®µéšSequentialå®Ÿè¡Œã§ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå›é¿
- React 19 + TypeScript + Viteã«ã‚ˆã‚‹ãƒ¢ãƒ€ãƒ³ãªã‚¦ã‚§ãƒ–ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
- Docker Composeã«ã‚ˆã‚‹2ã‚µãƒ¼ãƒ“ã‚¹æ§‹æˆï¼ˆPython + nginxï¼‰
- æ—¥æœ¬èªè²¡å‹™ãƒ‡ãƒ¼ã‚¿ã®å®Œå…¨ã‚µãƒãƒ¼ãƒˆ

**ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ:**
- **é–‹ç™º**: Vite dev server (port 5173) + Vite preview (port 4173)
- **æœ¬ç•ª**: nginx production server (port 8080) via Docker Compose

è©³ç´°ã¯[DOCKER.md](DOCKER.md)ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

## ğŸ”„ Architecture Overview (Updated 2025-10-20)

### System Architecture Summary

**yfinance-jp-screener** ã¯ã€æ—¥æœ¬æ ªå¼å¸‚å ´ã®3795+éŠ˜æŸ„ã‚’è‡ªå‹•åé›†ãƒ»åˆ†æã™ã‚‹ãƒ•ãƒ«ã‚¹ã‚¿ãƒƒã‚¯æ ªå¼ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã§ã™ã€‚

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    GitHub Actions Workflows                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ Part 1/4   â”‚â†’ â”‚ Part 2/4   â”‚â†’ â”‚ Part 3/4   â”‚â†’ â”‚ Part 4/4   â”‚â”‚
â”‚  â”‚ stocks_1   â”‚  â”‚ stocks_2   â”‚  â”‚ stocks_3   â”‚  â”‚ stocks_4   â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                                         â†“        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ CSV Combine & Export â†’ YYYYMMDD_combined.csv          â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Local Development                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  stock_list/            â”‚    â”‚  stock_search/          â”‚    â”‚
â”‚  â”‚  (Python 3.11)          â”‚    â”‚  (React 19 + TS)        â”‚    â”‚
â”‚  â”‚  â”œâ”€ sumalize.py         â”‚    â”‚  â”œâ”€ DataPage.tsx        â”‚    â”‚
â”‚  â”‚  â”œâ”€ combine_csv.py      â”‚    â”‚  â”œâ”€ FileUpload.tsx      â”‚    â”‚
â”‚  â”‚  â””â”€ Export/*.csv        â”‚    â”‚  â””â”€ CSVViewer.tsx       â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Docker Production                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  Python Service         â”‚    â”‚  Frontend Service       â”‚    â”‚
â”‚  â”‚  (Dockerfile.fetch)     â”‚    â”‚  (Dockerfile.app)       â”‚    â”‚
â”‚  â”‚  â”œâ”€ Data Collection     â”‚    â”‚  â”œâ”€ nginx:alpine        â”‚    â”‚
â”‚  â”‚  â”œâ”€ CSV Generation      â”‚    â”‚  â”œâ”€ Static Files        â”‚    â”‚
â”‚  â”‚  â””â”€ Export/ â†’ volume    â”‚â†â”€â”€â†’â”‚  â””â”€ Drag & Drop UI      â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚              stock-data volume (named Docker volume)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
                   Browser: http://localhost:8080
```

### Core Components

#### 1. **Data Collection Pipeline** (stock_list/)
- **Purpose**: JPXå…¬å¼ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰3795+éŠ˜æŸ„ã®è²¡å‹™ãƒ‡ãƒ¼ã‚¿è‡ªå‹•åé›†
- **Technology**: Python 3.11, yfinance, pandas
- **Key Scripts**:
  - `sumalize.py` - yfinance APIã«ã‚ˆã‚‹è²¡å‹™ãƒ‡ãƒ¼ã‚¿åé›†
  - `get_jp_stocklist.py` - JPXå…¬å¼æ ªå¼ãƒªã‚¹ãƒˆå–å¾—
  - `combine_latest_csv.py` - CSVçµ±åˆå‡¦ç†
  - `split_stocks.py` - æ ªå¼ãƒªã‚¹ãƒˆåˆ†å‰²ï¼ˆCLIå¯¾å¿œï¼‰
- **Output**: `Export/YYYYMMDD_combined.csv` (ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãçµ±åˆCSV)

#### 2. **Web Application** (stock_search/)
- **Purpose**: ãƒ‰ãƒ©ãƒƒã‚°&ãƒ‰ãƒ­ãƒƒãƒ—ã«ã‚ˆã‚‹CSVãƒ•ã‚¡ã‚¤ãƒ«åˆ†æUI
- **Technology**: React 19, TypeScript, Vite, Tailwind CSS, DaisyUI
- **Architecture**:
  ```
  src/
  â”œâ”€â”€ pages/
  â”‚   â””â”€â”€ DataPage.tsx         # ãƒ¡ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ï¼ˆD&Dã‚¨ãƒªã‚¢ + ãƒ‡ãƒ¼ã‚¿è¡¨ç¤ºï¼‰
  â”œâ”€â”€ components/
  â”‚   â”œâ”€â”€ FileUpload.tsx       # D&Dãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
  â”‚   â”œâ”€â”€ CSVViewer.tsx        # ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤º
  â”‚   â”œâ”€â”€ DataTable.tsx        # å‹•çš„ã‚«ãƒ©ãƒ æ¤œå‡º
  â”‚   â”œâ”€â”€ SearchFilters.tsx    # æ¤œç´¢ãƒ»ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
  â”‚   â””â”€â”€ Pagination.tsx       # ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³
  â”œâ”€â”€ hooks/
  â”‚   â”œâ”€â”€ useCSVParser.ts      # CSVè§£æãƒ­ã‚¸ãƒƒã‚¯
  â”‚   â””â”€â”€ useFilters.ts        # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°çŠ¶æ…‹ç®¡ç†
  â””â”€â”€ utils/
      â”œâ”€â”€ csvParser.ts         # PapaParseçµ±åˆ
      â”œâ”€â”€ csvDownload.ts       # CSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
      â””â”€â”€ columnConfig.ts      # ã‚«ãƒ©ãƒ è¨­å®š
  ```
- **Key Features**:
  - å®Œå…¨ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚µã‚¤ãƒ‰å‡¦ç†ï¼ˆã‚µãƒ¼ãƒãƒ¼ä¸è¦ï¼‰
  - ä»»æ„ã®CSVæ§‹é€ ã«å¯¾å¿œï¼ˆå‹•çš„ã‚«ãƒ©ãƒ æ¤œå‡ºï¼‰
  - æ—¥æœ¬èªè²¡å‹™ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¯¾å¿œï¼ˆå††ã€%ã€å€ï¼‰
  - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¤œç´¢ãƒ»ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
  - ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–ãƒ‡ã‚¶ã‚¤ãƒ³ï¼ˆãƒ¢ãƒã‚¤ãƒ«å¯¾å¿œï¼‰

#### 3. **Docker Environment**
- **Architecture**: 2ã‚µãƒ¼ãƒ“ã‚¹æ§‹æˆ + å…±æœ‰ãƒœãƒªãƒ¥ãƒ¼ãƒ 
- **Services**:
  1. **Python Service** (Dockerfile.fetch)
     - Base: `python:3.11-slim`
     - Purpose: ãƒ‡ãƒ¼ã‚¿åé›†ãƒ»CSVç”Ÿæˆ
     - Volume: `stock-data:/app/Export:rw`
  2. **Frontend Service** (Dockerfile.app)
     - Base: `nginx:alpine` (multi-stage build)
     - Purpose: é™çš„ãƒ•ã‚¡ã‚¤ãƒ«é…ä¿¡
     - Volume: `stock-data:/usr/share/nginx/html/csv:ro`
- **Data Flow**:
  ```
  Python Container â†’ Export/*.csv â†’ stock-data volume
                                        â†“
  Frontend Container â† /usr/share/nginx/html/csv â† stock-data volume
                                        â†“
                        Browser: http://localhost:8080
  ```

#### 4. **GitHub Actions CI/CD**
- **7 Workflows** ã«ã‚ˆã‚‹å®Œå…¨è‡ªå‹•åŒ–ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
- **Sequential Execution**: 4æ®µéšãƒ‡ãƒ¼ã‚¿åé›†ï¼ˆå„120åˆ†ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼‰
- **Workflow Chain**:
  1. `stock-fetch-sequential-1.yml` (Manual Start) â†’ stocks_1.json
  2. `stock-fetch-sequential-2.yml` (Auto-trigger) â†’ stocks_2.json
  3. `stock-fetch-sequential-3.yml` (Auto-trigger) â†’ stocks_3.json
  4. `stock-fetch-sequential-4.yml` (Auto-trigger) â†’ stocks_4.json
  5. `csv-combine-export.yml` (Auto-trigger) â†’ YYYYMMDD_combined.csv
- **Additional Workflows**:
  - `stock-data-fetch.yml` - å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«æ‰‹å‹•å®Ÿè¡Œ
  - `stock-list-update.yml` - JPXæ ªå¼ãƒªã‚¹ãƒˆæ›´æ–°

### Technology Stack Summary

| Layer | Technology | Purpose |
|-------|-----------|---------|
| **Backend** | Python 3.11 | ãƒ‡ãƒ¼ã‚¿åé›†ãƒ»å‡¦ç† |
| **Data Source** | yfinance API | è²¡å‹™ãƒ‡ãƒ¼ã‚¿å–å¾— |
| **Data Processing** | pandas | CSVå‡¦ç†ãƒ»çµ±åˆ |
| **Frontend** | React 19 + TypeScript | UIãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ |
| **Build Tool** | Vite | é«˜é€Ÿãƒ“ãƒ«ãƒ‰ãƒ»HMR |
| **Styling** | Tailwind CSS + DaisyUI | ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–ãƒ‡ã‚¶ã‚¤ãƒ³ |
| **CSV Parser** | PapaParse | ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚µã‚¤ãƒ‰CSVè§£æ |
| **Deployment** | Docker + nginx | æœ¬ç•ªç’°å¢ƒã‚³ãƒ³ãƒ†ãƒŠåŒ– |
| **CI/CD** | GitHub Actions | è‡ªå‹•ãƒ‡ãƒ¼ã‚¿åé›† |
| **Version Control** | Git + GitHub | ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ç®¡ç† |

### Data Architecture

#### Stock Data Structure (CSV Format)
```csv
ä¼šç¤¾å,éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰,æ¥­ç¨®,å„ªå…ˆå¸‚å ´,æ™‚ä¾¡ç·é¡,æ±ºç®—æœˆ,éƒ½é“åºœçœŒ,ä¼šè¨ˆåŸºæº–,
PBR,ROE,è‡ªå·±è³‡æœ¬æ¯”ç‡,PER(ä¼šäºˆ),å£²ä¸Šé«˜,å–¶æ¥­åˆ©ç›Š,å–¶æ¥­åˆ©ç›Šç‡,å½“æœŸç´”åˆ©ç›Š,
ç´”åˆ©ç›Šç‡,è² å‚µ,æµå‹•è² å‚µ,æµå‹•è³‡ç”£,ãƒãƒƒãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥,ãƒãƒƒãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥æ¯”ç‡,
ç·è² å‚µ,ç¾é‡‘åŠã³ç¾é‡‘åŒç­‰ç‰©,æŠ•è³‡æœ‰ä¾¡è¨¼åˆ¸
```

#### Data Flow Pipeline
```
JPX Official Data (Excel) â†’ get_jp_stocklist.py â†’ stocks_all.json (3795+ companies)
                                                        â†“
                              split_stocks.py â†’ stocks_1-4.json (1000 companies each)
                                                        â†“
        yfinance API â† sumalize.py (Sequential 4-part execution, ~3-4 hours total)
                                                        â†“
              japanese_stocks_data_1-4_YYYYMMDD_HHMMSS.csv (Timestamped outputs)
                                                        â†“
                   combine_latest_csv.py â†’ YYYYMMDD_combined.csv (Single merged file)
                                                        â†“
                            Docker Volume or Local Export/ directory
                                                        â†“
                   Frontend: Drag & Drop â†’ PapaParse â†’ DataTable Display
```

### Key Design Decisions

#### âœ… **Simplified CSV Handling (2025-10-19 Update)**
- **Before**: è‡ªå‹•æ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ  + prebuild scripts
- **After**: Drag & Dropå°‚ç”¨ã‚·ã‚¹ãƒ†ãƒ 
- **Benefits**:
  - ã‚µãƒ¼ãƒãƒ¼è¨­å®šä¸è¦ï¼ˆå®Œå…¨ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚µã‚¤ãƒ‰ï¼‰
  - ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ä¿è­·ï¼ˆãƒ‡ãƒ¼ã‚¿ã¯ãƒ–ãƒ©ã‚¦ã‚¶å†…ã®ã¿ã§å‡¦ç†ï¼‰
  - æŸ”è»Ÿæ€§ï¼ˆä»»æ„ã®CSVæ§‹é€ ã«å¯¾å¿œï¼‰
  - ãƒ‡ãƒ—ãƒ­ã‚¤ç°¡ç´ åŒ–ï¼ˆé™çš„ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ï¼‰
  - ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ãƒ•ãƒªãƒ¼ï¼ˆprebuildã‚¹ã‚¯ãƒªãƒ—ãƒˆä¸è¦ï¼‰

#### âœ… **Sequential GitHub Actions Workflow**
- **Why**: API rate limitingå›é¿ + GitHub Actions 6æ™‚é–“åˆ¶é™å¯¾å¿œ
- **How**: 4æ®µéšè‡ªå‹•é€£é–å®Ÿè¡Œï¼ˆå„120åˆ†ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼‰
- **Benefits**: å®‰å®šæ€§ã€ç›£è¦–å¯èƒ½æ€§ã€æ®µéšçš„ã‚³ãƒŸãƒƒãƒˆ

#### âœ… **Docker Two-Service Architecture**
- **Why**: ãƒ‡ãƒ¼ã‚¿åé›†ã¨ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã®åˆ†é›¢
- **How**: Named volumeå…±æœ‰ï¼ˆstock-dataï¼‰
- **Benefits**: ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ€§ã€å†åˆ©ç”¨æ€§ã€ç’°å¢ƒä¸€è²«æ€§

#### âœ… **Client-Side CSV Processing**
- **Why**: ã‚µãƒ¼ãƒãƒ¼ãƒ¬ã‚¹ã€é«˜é€Ÿã€ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼
- **How**: PapaParse library + React hooks
- **Benefits**: å³åº§ã®å‡¦ç†ã€æŸ”è»Ÿãªæ§‹é€ å¯¾å¿œã€ãƒ‡ãƒ—ãƒ­ã‚¤ç°¡å˜

### Performance Considerations

- **Data Volume**: 3795+ companies Ã— 30+ financial metrics
- **Collection Time**: ~3-4 hours for full dataset (via GitHub Actions)
- **API Rate**: ~3-5 seconds per company (yfinance throttling)
- **CSV Size**: ~1-2 MB per combined file
- **Build Time**: ~1-2 minutes (Vite optimization)
- **Bundle Size**: Vendor chunks separated for caching efficiency

### Security & Compliance

- **API Usage**: yfinance rate limiting compliance
- **Data Privacy**: ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚µã‚¤ãƒ‰å‡¦ç†ï¼ˆã‚µãƒ¼ãƒãƒ¼é€ä¿¡ãªã—ï¼‰
- **Docker Security**: Non-root users, minimal base images
- **Version Control**: Complete audit trail
- **Access Control**: GitHub repository permissions

## ğŸ†• Recent Updates (2025-10-19)

### Drag & Drop File Upload System

**å¤‰æ›´æ¦‚è¦**: CSVè‡ªå‹•æ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ ã‚’å‰Šé™¤ã—ã€ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ‰ãƒ©ãƒƒã‚°&ãƒ‰ãƒ­ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å°‚ç”¨ã«å¤‰æ›´ã—ã¾ã—ãŸã€‚

#### ä¸»è¦ãªå¤‰æ›´ç‚¹

**1. å‰Šé™¤ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«:**
- `stock_search/src/hooks/useCSVFileDetector.ts` - è‡ªå‹•æ¤œå‡ºãƒ•ãƒƒã‚¯ã®å‰Šé™¤
- `stock_search/scripts/copy-csv-files.js` - prebuildã‚¹ã‚¯ãƒªãƒ—ãƒˆã®å‰Šé™¤
- `package.json` - `prebuild`ãŠã‚ˆã³`copy-csv`ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®å‰Šé™¤

**2. DataPage.tsx ã®ç°¡ç´ åŒ–**
- **å ´æ‰€**: `stock_search/src/pages/DataPage.tsx`
- **å¤‰æ›´å†…å®¹**:
  - `useCSVFileDetector`ãƒ•ãƒƒã‚¯ã®ä½¿ç”¨ã‚’å‰Šé™¤
  - ãƒ•ã‚¡ã‚¤ãƒ«è‡ªå‹•æ¤œå‡ºãƒ­ã‚¸ãƒƒã‚¯ã®å‰Šé™¤
  - D&Då°‚ç”¨UIã«å¤‰æ›´
  - ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±è¡¨ç¤ºã®è¿½åŠ ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«åã€ã‚µã‚¤ã‚ºã€æ›´æ–°æ—¥ï¼‰
  - ãƒ•ã‚¡ã‚¤ãƒ«é–‰ã˜ã‚‹ãƒœã‚¿ãƒ³ã®è¿½åŠ 

**3. æ–°ã—ã„ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ãƒ­ãƒ¼**
```
ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•
    â†“
D&Dã‚¨ãƒªã‚¢ã‚’è¡¨ç¤º
    â†“
ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒCSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‰ãƒ©ãƒƒã‚°&ãƒ‰ãƒ­ãƒƒãƒ—
ã¾ãŸã¯
ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ
    â†“
FileUpload ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆãŒãƒ•ã‚¡ã‚¤ãƒ«ã‚’å—ä¿¡
    â†“
handleFileUpload ã§CSVFileå½¢å¼ã«å¤‰æ›
    â†“
CSVViewer ã§ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º
```

#### ãƒ¡ãƒªãƒƒãƒˆ

âœ… **ã‚·ãƒ³ãƒ—ãƒ«**: ã‚µãƒ¼ãƒãƒ¼è¨­å®šä¸è¦ã€å®Œå…¨ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚µã‚¤ãƒ‰
âœ… **ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼**: ãƒ‡ãƒ¼ã‚¿ã¯ãƒ–ãƒ©ã‚¦ã‚¶å†…ã®ã¿ã§å‡¦ç†ï¼ˆã‚µãƒ¼ãƒãƒ¼é€ä¿¡ãªã—ï¼‰
âœ… **æŸ”è»Ÿæ€§**: ä»»æ„ã®CSVæ§‹é€ ã«å¯¾å¿œ
âœ… **é«˜é€Ÿ**: å³åº§ã«ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†é–‹å§‹
âœ… **ãƒ‡ãƒ—ãƒ­ã‚¤ç°¡å˜**: é™çš„ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ï¼ˆGitHub Pages, S3, netlifyãªã©ï¼‰
âœ… **ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ãƒ•ãƒªãƒ¼**: prebuildã‚¹ã‚¯ãƒªãƒ—ãƒˆä¸è¦

#### ãƒ“ãƒ«ãƒ‰ãƒ—ãƒ­ã‚»ã‚¹ã®ç°¡ç´ åŒ–

**Before (è‡ªå‹•æ¤œå‡ºæ™‚):**
```bash
npm run build
  â†“
prebuild: node scripts/copy-csv-files.js
  â†“
tsc -b && vite build
```

**After (D&Då°‚ç”¨):**
```bash
npm run build
  â†“
tsc -b && vite build
```

#### UIæ”¹å–„

- **åˆå›è¡¨ç¤º**: D&Dæ¡ˆå†…ã¨ä½¿ã„æ–¹ã‚¬ã‚¤ãƒ‰
- **ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠå¾Œ**: ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚«ãƒ¼ãƒ‰è¡¨ç¤º
- **ãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œ**: é–‰ã˜ã‚‹ãƒœã‚¿ãƒ³ã§åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã«åˆ‡ã‚Šæ›¿ãˆå¯èƒ½
- **ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°**: ä¸æ­£ãªãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã®ã‚¨ãƒ©ãƒ¼è¡¨ç¤º

## Support / å¯„ä»˜

ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãŒå½¹ç«‹ã¤å ´åˆã¯ã€ã‚µãƒãƒ¼ãƒˆã‚’ã”æ¤œè¨ãã ã•ã„ã€‚

[![GitHub Sponsors](https://img.shields.io/badge/Sponsor-GitHub-pink?style=for-the-badge&logo=github)](https://github.com/sponsors/testkun08080)
[![Buy Me A Coffee](https://img.shields.io/badge/Buy%20Me%20A%20Coffee-Support-yellow?style=for-the-badge&logo=buy-me-a-coffee)](https://www.buymeacoffee.com/testkun08080)

**å¯„ä»˜æ–¹æ³•:**
- **GitHub Sponsors**: ç¶™ç¶šçš„ãªã‚µãƒãƒ¼ãƒˆã€æœˆé¡ãƒ—ãƒ©ãƒ³ã‚ã‚Š
- **Buy Me a Coffee**: ä¸€å›é™ã‚Šã®å¯„ä»˜ã€æ„Ÿè¬ã®æ°—æŒã¡ã‚’ä¼ãˆã‚‹

ã”æ”¯æ´ã„ãŸã ã„ãŸã‚µãƒãƒ¼ãƒˆã¯ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ç¶™ç¶šçš„ãªé–‹ç™ºã¨æ”¹å–„ã«ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚
